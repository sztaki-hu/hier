process_0: 
  general:
    seednum: 1 
  agent: 
    type: ['sac'] # ['sac','td3','ddpg']
    sac:
      alpha: [0.1]  #gymmaze 0.2 #robot 0.1
    gamma: [0.99]   #gymmaze 0.99 x robot 0.95
    learning_rate: [0.001]
  environment:
    task:
      params:
        gymmaze:
          maze_map: ['7x7_base','7x7_wall','7x7_S','7x7_S_fix']
    reward:
      reward_shaping_type: ['sparse'] # sparse / state_change_bonus
      reward_bonus: [0.0] #--- only if reward_shaping_type == state_change_bonus
  buffer:
    replay_buffer_size: [1e6]
    her:
      goal_selection_strategy: ['noher'] # final  ######################## HER ################
    hier:
      buffer_size: [1e6]
      lambda: # threshold
        mode: ['nohier']    ######################## HiER ################
        fix:
          lambda: [-20] # gympanda: -20
        predefined: 
          lambda_start: [-50] # gympanda: -50; gym: -100
          lambda_end: [-10] # gympanda: -10; gym: -10
      xi: # hier batch ratio 
        mode: ['fix'] # fix 
        xi: [0.5]     
    per:
      mode: ['noper'] # proportional               ######################## PER ################
  trainer:
    total_timesteps: [5e2]
  eval:
    freq: [5e1]
    num_episodes: [10]
  # structure is differend than in the config file #################################
  task:
    # gympanda: ['PandaReach-v3','PandaPush-v3','PandaSlide-v3',
    #           'PandaPickAndPlace-v3','PandaStack-v3', 'PandaFlip-v3']
    gymmaze: ['PointMaze_UMaze-v3'] #['PointMaze_UMaze-v3','AntMaze_UMaze-v4', AntMaze_UMazeDense-v4]
    #gymfetch: ['FetchReach-v2', 'FetchPush-v2','FetchSlide-v2','FetchPickAndPlace-v2']
  ise: 
    type: ['max']
    # type: ['max','min',
    #              'predefined','predefined2stage','predefined3stage',
    #              'selfpaced','control', 'controladaptive'] ######################## E2H-ISE  ################## 
    range_growth_mode: ['simple'] 
####################################################################################


