
# ['PandaReach-v3','PandaPush-v3','PandaSlide-v3','PandaPickAndPlace-v3','PandaStack-v3']

process_0:
  agent: 
    type: ['sac']
  environment:
    reward:
      reward_bonus: [0.1]
  buffer:
    replay_buffer_size: [1e6]
    her:
      goal_selection_strategy: ['final']
    highlights:
      batch_ratio: [0.5]
  trainer:
    total_timesteps: [5e4]
  # structure is differend than in the config file ##################################################x
  task: 
    gympanda: ['PandaReach-v3']
  cl: 
    type: ['controldiscreteadaptive','controldiscrete_const','predefined_linear','nocl','predefinedtwostage_linear','predefinedthreestage_linear']
    range_growth_mode: ['simple']
  ####################################################################################################

process_1:
  agent: 
    type: ['sac']
  environment:
    reward:
      reward_bonus: [0.1]
  buffer:
    replay_buffer_size: [1e6]
    her:
      goal_selection_strategy: ['final']
    highlights:
      batch_ratio: [0.5]
  trainer:
    total_timesteps: [5e5]
  # structure is differend than in the config file ##################################################x
  task: 
    gympanda: ['PandaPush-v3']
  cl: 
    type: ['controldiscreteadaptive','controldiscrete_const','predefined_linear','nocl']
    range_growth_mode: ['simple']
  ####################################################################################################

process_2:
  agent: 
    type: ['sac']
  environment:
    reward:
      reward_bonus: [0.1]
  buffer:
    replay_buffer_size: [1e6]
    her:
      goal_selection_strategy: ['final']
    highlights:
      batch_ratio: [0.5]
  trainer:
    total_timesteps: [5e5]
  # structure is differend than in the config file ##################################################x
  task: 
    gympanda: ['PandaSlide-v3',]
  cl: 
    type: ['controldiscreteadaptive','controldiscrete_const','predefined_linear','nocl']
    range_growth_mode: ['simple']
  ####################################################################################################

process_3:
  agent: 
    type: ['sac']
  environment:
    reward:
      reward_bonus: [0.1]
  buffer:
    replay_buffer_size: [1e6]
    her:
      goal_selection_strategy: ['final']
    highlights:
      batch_ratio: [0.5]
  trainer:
    total_timesteps: [5e5]
  # structure is differend than in the config file ##################################################x
  task: 
    gympanda: [PandaPickAndPlace-v3]
  cl: 
    type: ['controldiscreteadaptive','controldiscrete_const','predefined_linear','nocl']
    range_growth_mode: ['simple']
  ####################################################################################################

process_4:
  agent: 
    type: ['sac']
  environment:
    reward:
      reward_bonus: [0.1]
  buffer:
    replay_buffer_size: [1e6]
    her:
      goal_selection_strategy: ['final']
    highlights:
      batch_ratio: [0.5]
  trainer:
    total_timesteps: [5e5]
  # structure is differend than in the config file ##################################################x
  task: 
    gympanda: ['PandaStack-v3']
  cl: 
    type: ['controldiscreteadaptive','controldiscrete_const','predefined_linear','nocl']
    range_growth_mode: ['simple']
  ####################################################################################################

process_5:
  agent: 
    type: ['sac']
  environment:
    reward:
      reward_bonus: [0.1]
  buffer:
    replay_buffer_size: [1e6]
    her:
      goal_selection_strategy: ['final']
    highlights:
      batch_ratio: [0.5]
  trainer:
    total_timesteps: [5e5]
  # structure is differend than in the config file ##################################################x
  task: 
    gympanda: ['PandaPush-v3','PandaSlide-v3']
  cl: 
    type: ['predefinedtwostage_linear','predefinedthreestage_linear']
    range_growth_mode: ['simple']
  ####################################################################################################

process_6:
  agent: 
    type: ['sac']
  environment:
    reward:
      reward_bonus: [0.1]
  buffer:
    replay_buffer_size: [1e6]
    her:
      goal_selection_strategy: ['final']
    highlights:
      batch_ratio: [0.5]
  trainer:
    total_timesteps: [5e5]
  # structure is differend than in the config file ##################################################x
  task: 
    gympanda: ['PandaPickAndPlace-v3','PandaStack-v3']
  cl: 
    type: ['predefinedtwostage_linear','predefinedthreestage_linear']
    range_growth_mode: ['simple']
  ####################################################################################################

process_7:
  agent: 
    type: ['sac']
  environment:
    reward:
      reward_bonus: [0.1]
  buffer:
    replay_buffer_size: [1e6]
    her:
      goal_selection_strategy: ['final']
    highlights:
      batch_ratio: [0.5]
  trainer:
    total_timesteps: [5e5]
  # structure is differend than in the config file ##################################################x
  task: 
    gympanda: ['PandaPush-v3','PandaSlide-v3']
  cl: 
    type: ['selfpaced','selfpaced_dual']
    range_growth_mode: ['simple']
  ####################################################################################################