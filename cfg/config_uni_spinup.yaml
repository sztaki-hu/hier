general:
  exp_name: 0725_X_01
  logdir: logs
  demodir: demos
  seed: 0

hardware:
  gpu: [0,1,2] 
  cpu_min: [1,1,1]
  cpu_max: [10,10,10]

environment:
  name: gympanda
  task: 
    name: PandaReach-v3
    params: []
  headless: True
  obs_dim: auto
  act_dim: auto
  reward:
    reward_scalor: 1
    reward_bonus: 0.1
    reward_shaping_type: sparse
  

agent:
  type: sac
  hidden_sizes: [256,256]
  boundary_min: auto
  boundary_max: auto
  gamma: 0.99 
  sac:
    n_step: 1
    polyak: 0.995
    lr: [0.001]
    alpha: [0.2]
  td3:
    target_noise: 0.2
    noise_clip: 0.5
    pi_lr : 0.001 
    q_lr : 0.001
    policy_delay : 2
    polyak : 0.995

buffer:
  replay_buffer_size: 100000

sampler:
  start_steps: 1000
  max_ep_len: auto

trainer:
  steps_per_epoch: 100
  epochs: 100
  batch_size: 100
  update_after: 1000
  update_every: 50

tester:
  num_test_episodes: 10

logger:
  model:
    save:
      mode: pi
      freq: 5
      best_after: 30